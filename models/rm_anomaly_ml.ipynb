{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from datetime import datetime,timedelta,date\n",
    "from collections import defaultdict\n",
    "\n",
    "#import colorlover as cl\n",
    "#import random\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "#import plotly\n",
    "#import plotly.graph_objs as go\n",
    "#from plotly import tools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../features/clear_data/rm_features.csv',';',infer_datetime_format=True,index_col=['time','host','consumer_group'],parse_dates=['time'])\n",
    "#df = pd.read_csv('../features/clear_data/rm_features.csv',';',infer_datetime_format=True,index_col=['time'],parse_dates=['time'])\n",
    "df = pd.read_csv('../features/clear_data/rm_features.csv',';',infer_datetime_format=True,parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cons=[(host,group) for host,group in df.drop_duplicates(['host','consumer_group'])[['host','consumer_group']].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame()\n",
    "X_pred=pd.DataFrame()\n",
    "for (host,consumer_group) in host_cons:\n",
    "    sample=df[(df.host==host)&(df.consumer_group==consumer_group)]\n",
    "    X_train=pd.concat([X_train,sample.head(int(len(sample)*0.97))],sort=False)\n",
    "    X_pred=pd.concat([X_pred,sample[~sample.index.isin(X_train.index)]],sort=False)\n",
    "#X_train=X_train.set_index(['time','host','consumer_group'])\n",
    "#X_pred=X_pred.set_index(['time','host','consumer_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить временной ряд на периоды с некоторым окном и свернуть каждый период с помощью PCA\n",
    "\n",
    "#ts_period=1 # количество дней \n",
    "#n_length=24 # количество часов\n",
    "\n",
    "\n",
    "#def window_stack(a, window=ts_period*n_length):\n",
    "    # разбиваем данные на окна длиной ts_period\n",
    "#    X=np.array([a[i:window+i] for i in range(int(len(a) - window))])\n",
    "#    return X\n",
    "\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#model_PCA = PCA(n_components=1)\n",
    "\n",
    "#for (host,consumer_group) in host_cons:\n",
    "#    samples=window_stack(df[(df.host==host)&(df.consumer_group==consumer_group)].set_index(['host','consumer_group']).values)\n",
    "    #model_PCA.fit_transform(df)\n",
    "#    for sample in samples:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.005\n",
    "def predict(model,X_train,X_pred=None,mode=0):\n",
    "    model_predict=pd.DataFrame()\n",
    "    for (host,consumer_group) in host_cons:\n",
    "        sample_train=X_train[(X_train.host==host)&(X_train.consumer_group==consumer_group)].set_index(['time','host','consumer_group'])\n",
    "        \n",
    "        if mode==0:\n",
    "            sample_pred=X_pred[(X_pred.host==host)&(X_pred.consumer_group==consumer_group)].set_index(['time','host','consumer_group'])\n",
    "            predict=model.fit(sample_train).predict(sample_pred)\n",
    "        else:\n",
    "            predict=model.fit_predict(sample_train)\n",
    "            \n",
    "        model_predict=pd.concat([model_predict,pd.DataFrame(predict,columns=['is_anomaly'])],sort=False)\n",
    "    return model_predict.reset_index(drop=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers_fraction = 0.005\n",
    "#def predict(model,X_train,X_pred):\n",
    "#    return pd.DataFrame(model.fit(X_train).predict(X_pred),columns=['is_anomaly'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "rns = np.random.RandomState(42)\n",
    "model_IF = IsolationForest(random_state=rns,contamination=outliers_fraction,n_estimators =100)\n",
    "\n",
    "anomaly_IF = predict(model_IF,X_train,X_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "model_LOF = LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction)\n",
    "anomaly_LOF = predict(model_LOF,df,mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model_SVM = svm.OneClassSVM(random_state=rns, nu=outliers_fraction, kernel=\"rbf\", gamma=0.01)\n",
    "anomaly_SVM = predict(model_SVM,X_train,X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JustMe\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\robust_covariance.py:622: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "model_EE = EllipticEnvelope(contamination=outliers_fraction)\n",
    "anomaly_EE = predict(model_EE,X_train,X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model_DBSCAN = DBSCAN(eps=4, min_samples=10)\n",
    "anomaly_DBSCAN = predict(model_DBSCAN,df,mode=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = []\n",
    "B = []\n",
    "C = []\n",
    "\n",
    "for i in np.linspace(0.1,5,50):\n",
    "    db = DBSCAN(eps=i, min_samples=10).fit(df[(df.host==1)&(df.consumer_group=='adw_unload_group')].set_index(['time','host','consumer_group']))\n",
    "\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    sum = 0\n",
    "    for t in labels:\n",
    "        if t == -1: \n",
    "            sum = sum + 1\n",
    "    C.append(sum)\n",
    "            \n",
    "    \n",
    "    \n",
    "    A.append(i)\n",
    "    B.append(int(n_clusters_))\n",
    "    \n",
    "results = pd.DataFrame([A,B,C]).T\n",
    "results.columns = ['distance','Number of clusters','Number of outliers']\n",
    "results.plot(x='distance',y='Number of clusters',figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [is_anomaly]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_DBSCAN[anomaly_DBSCAN.is_anomaly==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#model_PCA = PCA(n_components=15, svd_solver='full')\n",
    "#model_PCA.fit_transform(df)\n",
    "\n",
    "#w_components_ = np.ones([model_PCA.n_components_, ])\n",
    "#selected_components_ = model_PCA.components_[-1 * model_PCA.n_selected_components_:, :]\n",
    "#selected_w_components_ = w_components_[-1 * model_PCA.n_selected_components_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>host</th>\n",
       "      <th>consumer_group</th>\n",
       "      <th>is_anomaly</th>\n",
       "      <th>is_anomaly_SVM</th>\n",
       "      <th>is_anomaly_EE</th>\n",
       "      <th>is_anomaly_LOF</th>\n",
       "      <th>is_anomalyDBSCAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-12-10 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2018-12-10 08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2018-12-10 08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>fp_dm_prior</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2018-12-10 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>hdp_unload_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2018-12-09 23:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2018-12-10 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2018-12-10 08:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2018-12-10 10:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2018-12-10 10:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>dm_tech_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2018-12-10 10:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>sandbox_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2018-12-10 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>adw_unload_group</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2018-12-10 10:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>dm_tech_group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  host    consumer_group  is_anomaly  is_anomaly_SVM  \\\n",
       "28  2018-12-10 23:00:00     1  adw_unload_group         NaN            -1.0   \n",
       "128 2018-12-10 08:00:00     2  adw_unload_group        -1.0            -1.0   \n",
       "157 2018-12-10 08:00:00     2       fp_dm_prior        -1.0            -1.0   \n",
       "178 2018-12-10 00:00:00     2  hdp_unload_group        -1.0            -1.0   \n",
       "234 2018-12-09 23:00:00     3  adw_unload_group        -1.0            -1.0   \n",
       "236 2018-12-10 01:00:00     3  adw_unload_group         NaN            -1.0   \n",
       "243 2018-12-10 08:00:00     3  adw_unload_group         NaN            -1.0   \n",
       "245 2018-12-10 10:00:00     3  adw_unload_group        -1.0            -1.0   \n",
       "274 2018-12-10 10:00:00     3     dm_tech_group        -1.0            -1.0   \n",
       "303 2018-12-10 10:00:00     3     sandbox_group        -1.0            -1.0   \n",
       "370 2018-12-10 19:00:00     4  adw_unload_group        -1.0             NaN   \n",
       "390 2018-12-10 10:00:00     4     dm_tech_group         NaN            -1.0   \n",
       "\n",
       "     is_anomaly_EE  is_anomaly_LOF  is_anomalyDBSCAN  \n",
       "28            -1.0             NaN               NaN  \n",
       "128           -1.0             NaN               NaN  \n",
       "157           -1.0             NaN               NaN  \n",
       "178            NaN             NaN               NaN  \n",
       "234           -1.0             NaN               NaN  \n",
       "236           -1.0             NaN               NaN  \n",
       "243           -1.0             NaN               NaN  \n",
       "245            NaN             NaN               NaN  \n",
       "274            NaN             NaN               NaN  \n",
       "303            NaN             NaN               NaN  \n",
       "370           -1.0             NaN               NaN  \n",
       "390           -1.0             NaN               NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=anomaly_IF[anomaly_IF.is_anomaly==-1]\\\n",
    "    .join(anomaly_SVM[anomaly_SVM.is_anomaly==-1],rsuffix ='_SVM',how='outer')\\\n",
    "    .join(anomaly_EE[anomaly_EE.is_anomaly==-1],rsuffix ='_EE',how='outer')\\\n",
    "    .join(anomaly_LOF[anomaly_LOF.is_anomaly==-1],rsuffix ='_LOF',how='outer')\\\n",
    "    .join(anomaly_DBSCAN[anomaly_DBSCAN.is_anomaly==-1],rsuffix ='_DBSCAN',how='outer')\n",
    "tmp=tmp[tmp.sum(axis=1)<-1]\n",
    "df_predict=X_pred.reset_index()[['time','host','consumer_group']].join(tmp,how='right')\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "dim=X_train.set_index(['time','host','consumer_group']).shape[1]\n",
    "\n",
    "X_input = Input(shape=(dim,))\n",
    "encoded = Dense(64, activation='relu', activity_regularizer=regularizers.l1(10e-5))(X_input)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(X_input, decoded)\n",
    "\n",
    "def autoencoder_fit_predict(model,X_train,X_pred):\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, X_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_pred, X_pred))\n",
    "    return model.predict(X_pred)\n",
    "\n",
    "model_predict=pd.DataFrame()\n",
    "for (host,consumer_group) in host_cons:\n",
    "    sample_train=X_train[(X_train.host==host)&(X_train.consumer_group==consumer_group)].set_index(['time','host','consumer_group'])\n",
    "    sample_pred=X_pred[(X_pred.host==host)&(X_pred.consumer_group==consumer_group)].set_index(['time','host','consumer_group'])\n",
    "    \n",
    "    sample_decoded=pd.DataFrame(autoencoder_fit_predict(autoencoder,sample_train,sample_pred),columns=sample_pred.columns)\n",
    "    autoencoder_predict=pd.concat([sample_pred.reset_index()[['time','host','consumer_group']],sample_decoded],axis=1,sort=False)\n",
    "\n",
    "    model_predict=pd.concat([model_predict,autoencoder_predict],sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(X_pred.drop(columns=['time','host','consumer_group']).values - model_predict.drop(columns=['time','host','consumer_group']).values, 2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse.loc[(3,'adw_unload_group')][['time']], mse.loc[(1,'adw_unload_group')][['mse']], '*')\n",
    "plt.xticks(rotation='vertical')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
