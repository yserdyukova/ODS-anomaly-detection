{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from datetime import date,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays={\n",
    "2018: {1:[1,2,3,4,5,6,7,8,13,14,20,21,27,28],2:[3,4,10,11,17,18,22,23,24,25],3:[3,4,7,8,9,10,11,17,18,24,25,31],4:[1,7,8,14,15,21,22,28,29,30],5:[1,2,5,6,8,9,12,13,19,20,26,27],6:[2,3,9,10,11,12,16,17,23,24,30],7:[1,7,8,14,15,21,22,28,29],8:[4,5,11,12,18,19,25,26],9:[1,2,8,9,15,16,22,23,29,30],10:[6,7,13,14,20,21,27,28],11:[3,4,5,10,11,17,18,24,25],12:[1,2,8,9,15,16,22,23,29,30,31]},\n",
    "2019: {1:[1,2,3,4,5,6,7,8,12,13,19,20,26,27],2:[2,3,9,10,16,17,22,23,24],3:[2,3,7,8,9,10,16,17,23,24,30,31],4:[6,7,13,14,20,21,27,28,30],5:[1,2,3,4,5,8,9,10,11,12,18,19,25,26],6:[1,2,8,9,11,12,15,16,22,23,29,30],7:[6,7,13,14,20,21,27,28],8:[3,4,10,11,17,18,24,25,31],9:[1,7,8,14,15,21,22,28,29],10:[5,6,12,13,19,20,26,27],11:[2,3,4,9,10,16,17,23,24,30],12:[1,7,8,14,15,21,22,28,29,31]},\n",
    "2020: {1:[1,2,3,4,5,6,7,8,11,12,18,19,25,26],2:[1,2,8,9,15,16,22,23,24,29],3:[1,7,8,9,14,15,21,22,28,29],4:[4,5,11,12,18,19,25,26,30],5:[1,2,3,8,9,10,11,16,17,23,24,30,31],6:[6,7,11,12,13,14,20,21,27,28],7:[4,5,11,12,18,19,25,26],8:[1,2,8,9,15,16,22,23,29,30],9:[5,6,12,13,19,20,26,27],10:[3,4,10,11,17,18,24,25,31],11:[1,3,4,7,8,14,15,21,22,28,29],12:[5,6,12,13,19,20,26,27,31]},\n",
    "2021: {1:[1,2,3,4,5,6,7,8,9,10,16,17,23,24,30,31],2:[6,7,13,14,20,21,22,23,27,28],3:[6,7,8,13,14,20,21,27,28],4:[3,4,10,11,17,18,24,25,30],5:[1,2,3,8,9,10,15,16,22,23,29,30],6:[5,6,11,12,13,14,19,20,26,27],7:[3,4,10,11,17,18,24,25,31],8:[1,7,8,14,15,21,22,28,29],9:[4,5,11,12,18,19,25,26],10:[2,3,9,10,16,17,23,24,30,31],11:[3,4,6,7,13,14,20,21,27,28],12:[4,5,11,12,18,19,25,26,31]}\n",
    "}\n",
    "holidays=pd.DataFrame(list(itertools.chain.from_iterable(list(itertools.chain.from_iterable([[[date(year,month,day) for day in days] for month,days in v.items()] for year,v in holidays.items()])))),columns=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filetodf(filename,time_list=[]):\n",
    "    # функция считывает файлы из директории и складывает данные в датафрейм\n",
    "    #  входные данные: \n",
    "    #     filename - путь к файлам\n",
    "    #     time_list - список полей с датой\n",
    "    #  выходные данные: \n",
    "    #     pd.dataframe\n",
    "    \n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    \n",
    "    AllFiles = glob.glob(filename)\n",
    "   \n",
    "    list_ = [pd.DataFrame()]\n",
    "\n",
    "    for file_ in AllFiles:\n",
    "        columns=pd.read_csv(file_, sep=',', nrows=0).columns.str.lower().str.strip()\n",
    "        df = pd.read_csv(file_,',',names=columns,parse_dates=time_list,dayfirst=True,skiprows=1)\n",
    "        list_.append(df)\n",
    "    \n",
    "    return pd.concat(list_, axis = 0, ignore_index = True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sysMetrics = filetodf('input/GrpStat_OSGLOB*.dat')\n",
    "df_grpMetrics = filetodf('input/GrpStat_RGALL*.dat')\n",
    "df_directives = filetodf('input/GrpStat_Directives*.dat',time_list=['begin_time'])\n",
    "\n",
    "df_sysMetrics.drop(['time'], axis=1,inplace=True)\n",
    "df_grpMetrics.drop(['t_beg'], axis=1,inplace=True)\n",
    "\n",
    "df_grpMetrics.rename(index=str, columns={\"instance_number\": \"host\", \"usr_group\": \"consumer_group\"}, inplace=True)\n",
    "df_directives.rename(index=str, columns={\"instance_number\": \"host\", \"begin_time\": \"time\"}, inplace=True)\n",
    "\n",
    "df_grpMetrics['consumer_group']=df_grpMetrics['consumer_group'].str.strip().str.lower()\n",
    "df_directives['consumer_group']=df_directives['consumer_group'].str.strip().str.lower()\n",
    "df_directives['plan_name']=df_directives['plan_name'].str.strip().str.lower()\n",
    "\n",
    "df_grpMetrics.replace(' None', np.NaN, inplace=True)\n",
    "df_directives.replace(' None', np.NaN, inplace=True)\n",
    "df_sysMetrics.replace(' None', np.NaN, inplace=True)\n",
    "\n",
    "df_directives.parallel_target_percentage=df_directives.parallel_target_percentage.astype(float)\n",
    "df_directives.parallel_degree_limit_p1=df_directives.parallel_degree_limit_p1.astype(float)\n",
    "df_directives.max_utilization_limit=df_directives.max_utilization_limit.astype(float)\n",
    "df_grpMetrics.pga=df_grpMetrics.pga.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#джойним все данные до уровня host, snap_id, consumer_group\n",
    "df=df_grpMetrics.set_index(['host','snap_id','consumer_group']) \\\n",
    ".join(df_directives.set_index(['host','snap_id','consumer_group']))\\\n",
    ".reset_index()\\\n",
    ".merge(df_sysMetrics,on=['host','snap_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df.consumer_group!='other_groups']\n",
    "#df = df[df.consumer_group!='ods2exa_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ресэмплинг до часа, чтобы сгладить ряд\n",
    "# заполняем отсутствующие значения средними\n",
    "# фильтруем неполные дни в начале и в конце\n",
    "\n",
    "df = df.sort_values(['host','consumer_group','time'])\n",
    "df = df.set_index(pd.DatetimeIndex(df['time']))\n",
    "#-----------------------------\n",
    "#df.loc[(df.consumer_group=='adw_unload_group')&(df.plan_name=='sandbox_plan'),'mgmt_p1']=26.\n",
    "#-----------------------------\n",
    "\n",
    "#df.max_utilization_limit.fillna(100,inplace=True)\n",
    "#df.parallel_target_percentage.fillna(100,inplace=True)\n",
    "#df.loc[:,'cpu_pct_maxul']=df.cpu/df.max_utilization_limit\n",
    "#df.loc[:,'px_pct_parallel']=df.pxqry/(df.parallel_target_percentage*1400.0/100.0)\n",
    "#df.loc[df.px_pct_parallel>2,'px_pct_parallel']=2.0\n",
    "#df.loc[df.cpu_pct_maxul>2,'cpu_pct_maxul']=2.0\n",
    "#df['CPU_min_treshold']=(df.mgmt_p1/df.max_utilization_limit)\n",
    "\n",
    "columns=df.columns.drop(['host','consumer_group','time','snap_id','plan_name'],errors='ignore')\n",
    "\n",
    "df=df.groupby(['host','consumer_group'])[columns].apply(lambda df: df.resample('H').mean().fillna(df.mean(axis=0))).reset_index(['host','consumer_group'])\n",
    "df=df.groupby(['host','consumer_group',df.index.date]).filter(lambda x: (x.index.min().hour==0)&(x.index.max().hour==23)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time\n",
       "0  2018-01-01\n",
       "1  2018-01-02\n",
       "2  2018-01-03\n",
       "3  2018-01-04\n",
       "4  2018-01-05"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime features\n",
    "\n",
    "    #day_of_month\n",
    "    #day_of_week\n",
    "    #month_of_year\n",
    "    #hour_of_day\n",
    "    #is_holiday\n",
    "    #quarter_of_year\n",
    "\n",
    "\n",
    "df.loc[:,('day_of_months')]=df.time.dt.day\n",
    "df.loc[:,('day_of_week')]=df.time.dt.dayofweek\n",
    "df.loc[:,('month_of_year')]=df.time.dt.month\n",
    "df.loc[:,('hour_of_day')]=df.time.dt.hour\n",
    "df.loc[:,('is_weekend')]=df.time.dt.dayofweek.isin([5,6])*1\n",
    "df.loc[:,('quarter_of_year')]=df.time.dt.quarter\n",
    "\n",
    "df['date']=df.time.dt.strftime('%Y-%m-%d')\n",
    "#df=df.loc[~df.date.isin(holidays.ds.values.astype('M8[D]'))].drop(columns=['date'])\n",
    "\n",
    "df = pd.merge(df,holidays,on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    2018-10-20\n",
       "101    2018-10-21\n",
       "102    2018-10-27\n",
       "103    2018-10-28\n",
       "104    2018-11-03\n",
       "105    2018-11-04\n",
       "106    2018-11-05\n",
       "107    2018-11-10\n",
       "108    2018-11-11\n",
       "109    2018-11-17\n",
       "110    2018-11-18\n",
       "111    2018-11-24\n",
       "112    2018-11-25\n",
       "113    2018-12-01\n",
       "114    2018-12-02\n",
       "115    2018-12-08\n",
       "116    2018-12-09\n",
       "117    2018-12-15\n",
       "118    2018-12-16\n",
       "119    2018-12-22\n",
       "120    2018-12-23\n",
       "121    2018-12-29\n",
       "122    2018-12-30\n",
       "123    2018-12-31\n",
       "124    2019-01-01\n",
       "125    2019-01-02\n",
       "126    2019-01-03\n",
       "127    2019-01-04\n",
       "128    2019-01-05\n",
       "129    2019-01-06\n",
       "          ...    \n",
       "460    2021-09-26\n",
       "461    2021-10-02\n",
       "462    2021-10-03\n",
       "463    2021-10-09\n",
       "464    2021-10-10\n",
       "465    2021-10-16\n",
       "466    2021-10-17\n",
       "467    2021-10-23\n",
       "468    2021-10-24\n",
       "469    2021-10-30\n",
       "470    2021-10-31\n",
       "471    2021-11-03\n",
       "472    2021-11-04\n",
       "473    2021-11-06\n",
       "474    2021-11-07\n",
       "475    2021-11-13\n",
       "476    2021-11-14\n",
       "477    2021-11-20\n",
       "478    2021-11-21\n",
       "479    2021-11-27\n",
       "480    2021-11-28\n",
       "481    2021-12-04\n",
       "482    2021-12-05\n",
       "483    2021-12-11\n",
       "484    2021-12-12\n",
       "485    2021-12-18\n",
       "486    2021-12-19\n",
       "487    2021-12-25\n",
       "488    2021-12-26\n",
       "489    2021-12-31\n",
       "Name: date, Length: 390, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays.date.loc[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-1d9631a8dfd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mholidays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# note this function has side effects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1057\u001b[0m                                      'of levels in the index of \"left\"')\n\u001b[0;32m   1058\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_on\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1060\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"len(right_on) must equal len(left_on)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "df['date']=df.time.dt.strftime('%Y-%m-%d')\n",
    "df = pd.merge(df,holidays,on ='date',how='left')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy features\n",
    "#df=pd.concat([df,pd.get_dummies(df[['host']].astype(str),prefix='host')],axis=1,sort=False)\n",
    "#df=pd.concat([df,pd.get_dummies(df[['consumer_group']],prefix='group')],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем лаги исходного ряда в качестве признаков\n",
    "for i in range(prediction_points, prediction_points+10):\n",
    "    df[\"lag_{}\".format(i)] = df.groupby(['host'])['sys_cpu'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_week_shift=df[columns].shift(24*7)\n",
    "#df_day_shift=df[columns].shift(24)\n",
    "#for (host,group) in df.drop_duplicates(['host','consumer_group'])[['host','consumer_group']].values:\n",
    "#    t=df[(df.host==host)&(df.consumer_group==group)][columns]\n",
    "#    for row in t.index:\n",
    "#        if t.loc[row].isnull().all():\n",
    "#            row_day=df_day_shift.loc[row,columns]\n",
    "#            row_week=df_week_shift.loc[row,columns]\n",
    "#            if row_week.isnull().all():\n",
    "#                if row_day.isnull().all():\n",
    "#                    df.loc[row,columns]=t.loc[:,columns].mean(axis=0)\n",
    "#                else:\n",
    "#                    df.loc[row,columns]=row_day\n",
    "#            else:\n",
    "#                df.loc[row,columns]=row_week\n",
    "#df.fillna(0,inplace=True)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_csv('clear_data/rm_features_ml.csv',';',index=False)\n",
    "df_nn.to_csv('clear_data/rm_features_nn.csv',';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
