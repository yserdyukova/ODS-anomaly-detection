{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import date,datetime\n",
    "from sklearn import preprocessing\n",
    "from contracts import contract, new_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_df(filename, time_list = []):    \n",
    "    ''' Read files from directory and put to pandas dataframe. \n",
    "            Input:\n",
    "                filename - path to files\n",
    "                time_list - date fields\n",
    "            Output:\n",
    "                pd.DataFrame() \n",
    "                \n",
    "    '''\n",
    "    \n",
    "    AllFiles = glob.glob(filename)    \n",
    "    assert len(AllFiles) > 0, 'No files in directory'\n",
    "   \n",
    "    list_ = [pd.DataFrame()]\n",
    "    for file_ in AllFiles:\n",
    "        columns = pd.read_csv(file_, sep=',', nrows=0).columns.str.lower().str.strip()\n",
    "        df = pd.read_csv(file_, ',', names=columns, parse_dates=time_list, dayfirst=True, skiprows=1)\n",
    "        list_.append(df)        \n",
    "    assert len(list_) > 0\n",
    "    \n",
    "    return pd.concat(list_, axis=0, ignore_index=True, sort=True)\n",
    "\n",
    "def read_files():\n",
    "    \n",
    "    df_sysMetrics = file_to_df('input/GrpStat_OSGLOB*.dat')\n",
    "    df_grpMetrics = file_to_df('input/GrpStat_RGALL*.dat')\n",
    "    df_directives = file_to_df('input/GrpStat_Directives*.dat', time_list=['begin_time'])\n",
    "    \n",
    "    df_sysMetrics.drop(['time'], axis=1, inplace=True)\n",
    "    df_grpMetrics.drop(['t_beg'], axis=1, inplace=True)\n",
    "    \n",
    "    df_grpMetrics.rename(index=str, columns={\"instance_number\": \"host\", \"usr_group\": \"consumer_group\"}, inplace=True)\n",
    "    df_directives.rename(index=str, columns={\"instance_number\": \"host\", \"begin_time\": \"time\"}, inplace=True)\n",
    "    \n",
    "    df_grpMetrics['consumer_group'] = df_grpMetrics['consumer_group'].str.strip().str.lower()\n",
    "    df_directives['consumer_group'] = df_directives['consumer_group'].str.strip().str.lower()\n",
    "    df_directives['plan_name'] = df_directives['plan_name'].str.strip().str.lower()\n",
    "    \n",
    "    df_grpMetrics.replace(' None', np.NaN, inplace=True)\n",
    "    df_directives.replace(' None', np.NaN, inplace=True)\n",
    "    df_sysMetrics.replace(' None', np.NaN, inplace=True)\n",
    "    \n",
    "    df_directives.parallel_target_percentage = df_directives.parallel_target_percentage.astype(float)\n",
    "    df_directives.parallel_degree_limit_p1 = df_directives.parallel_degree_limit_p1.astype(float)\n",
    "    df_directives.max_utilization_limit = df_directives.max_utilization_limit.astype(float)\n",
    "    df_grpMetrics.pga = df_grpMetrics.pga.astype(float)\n",
    "    \n",
    "    return df_grpMetrics.set_index(['host','snap_id','consumer_group']) \\\n",
    "        .join(df_directives.set_index(['host','snap_id','consumer_group']))\\\n",
    "        .reset_index()\\\n",
    "        .merge(df_sysMetrics,on=['host','snap_id'])\n",
    "        \n",
    "def prepare_features(df, group_excl):\n",
    "\n",
    "    columns = df.columns.drop(['snap_id','plan_name','max_utilization_limit', \n",
    "                         'mgmt_p1', 'parallel_degree_limit_p1', 'parallel_target_percentage','pxenq',\n",
    "                         'sys_dbtime','sys_actsess_avg'],errors='ignore')\n",
    "\n",
    "    #return df.set_index(pd.DatetimeIndex(df['time'])).loc[~df.consumer_group.isin(group_excl),[columns]]\n",
    "    return df.loc[~df.consumer_group.isin(group_excl),columns]\n",
    "\n",
    "\n",
    "def sample_features(df):\n",
    "    \n",
    "    ''' Resample to smooze time series.\n",
    "        Drop rows with NA values.\n",
    "    \n",
    "    '''\n",
    "    #df=df.groupby(['host','consumer_group',df.index.date]).filter(lambda x: (x.index.min().hour==0)&(x.index.max().hour==23)).reset_index()\n",
    "    return df.set_index(['host','consumer_group']).groupby(level=['host','consumer_group']).apply(lambda c: c.set_index(pd.DatetimeIndex(c['time'])).resample('3H').mean()).reset_index().dropna()\n",
    "\n",
    "def scale_features(df):\n",
    "    \n",
    "    ''' Scale values by every consumer_group and host.\n",
    "    \n",
    "    '''\n",
    "    host_cons = [(host,group) for host,group in df.drop_duplicates(['host','consumer_group'])[['host','consumer_group']].values]\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    df_scaled = pd.DataFrame()\n",
    "    for (host,consumer_group) in host_cons:\n",
    "        df_sample = df[(df.host == host)&(df.consumer_group == consumer_group)].set_index(['host','consumer_group','time'])\n",
    "        df_sample = pd.concat([df_sample.reset_index()[['host','consumer_group','time']],pd.DataFrame(scaler.fit_transform(df_sample),columns=df_sample.columns)],axis=1,sort=False)\n",
    "        df_scaled = pd.concat([df_scaled,df_sample],sort=False)\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "def dummy_features(df, holidays):\n",
    "    \n",
    "    ''' Get dummy features.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_dummy=df.copy(deep=True)\n",
    "    \n",
    "    df_dummy.loc[:, ('day_of_week')] = df_dummy.time.dt.dayofweek\n",
    "    df_dummy.loc[:, ('hour_of_day')] = df_dummy.time.dt.hour\n",
    "    df_dummy.loc[:, ('is_weekend')] = df_dummy.time.dt.dayofweek.isin([5,6])*1\n",
    "    #df_dummy.loc[:, ('week_of_month')] = (df_dummy.time.dt.day - 1)//7 + 1\n",
    "    #df_dummy.loc[:,('month_of_year')]=df_dummy.time.dt.month\n",
    "    #df_dummy.loc[:,('quarter_of_year')]=df_dummy.time.dt.quarter\n",
    "    df_dummy.loc[:,('day_of_month')] = df_dummy.time.dt.day\n",
    "    \n",
    "    df_dummy['date'] = pd.to_datetime(df_dummy.time.dt.strftime('%Y-%m-%d'))\n",
    "    df_dummy = df_dummy.merge(holidays,on='date', how='left').drop(columns=['date'])\n",
    "    df_dummy.loc[:, ('is_holiday')].fillna(0, inplace=True)\n",
    "    \n",
    "    # dummy features\n",
    "    dummy_columns = ['day_of_month', 'day_of_week', 'hour_of_day']\n",
    "    df_dummy = pd.get_dummies(df_dummy.astype(str),\n",
    "                             columns=dummy_columns,\n",
    "                             prefix=dummy_columns,\n",
    "                             drop_first=True)\n",
    "    \n",
    "    return df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = {\n",
    "2018: {1:[1,2,3,4,5,6,7,8,13,14,20,21,27,28],2:[3,4,10,11,17,18,22,23,24,25],3:[3,4,7,8,9,10,11,17,18,24,25,31],4:[1,7,8,14,15,21,22,28,29,30],5:[1,2,5,6,8,9,12,13,19,20,26,27],6:[2,3,9,10,11,12,16,17,23,24,30],7:[1,7,8,14,15,21,22,28,29],8:[4,5,11,12,18,19,25,26],9:[1,2,8,9,15,16,22,23,29,30],10:[6,7,13,14,20,21,27,28],11:[3,4,5,10,11,17,18,24,25],12:[1,2,8,9,15,16,22,23,29,30,31]},\n",
    "2019: {1:[1,2,3,4,5,6,7,8,12,13,19,20,26,27],2:[2,3,9,10,16,17,22,23,24],3:[2,3,7,8,9,10,16,17,23,24,30,31],4:[6,7,13,14,20,21,27,28,30],5:[1,2,3,4,5,8,9,10,11,12,18,19,25,26],6:[1,2,8,9,11,12,15,16,22,23,29,30],7:[6,7,13,14,20,21,27,28],8:[3,4,10,11,17,18,24,25,31],9:[1,7,8,14,15,21,22,28,29],10:[5,6,12,13,19,20,26,27],11:[2,3,4,9,10,16,17,23,24,30],12:[1,7,8,14,15,21,22,28,29,31]},\n",
    "2020: {1:[1,2,3,4,5,6,7,8,11,12,18,19,25,26],2:[1,2,8,9,15,16,22,23,24,29],3:[1,7,8,9,14,15,21,22,28,29],4:[4,5,11,12,18,19,25,26,30],5:[1,2,3,8,9,10,11,16,17,23,24,30,31],6:[6,7,11,12,13,14,20,21,27,28],7:[4,5,11,12,18,19,25,26],8:[1,2,8,9,15,16,22,23,29,30],9:[5,6,12,13,19,20,26,27],10:[3,4,10,11,17,18,24,25,31],11:[1,3,4,7,8,14,15,21,22,28,29],12:[5,6,12,13,19,20,26,27,31]},\n",
    "2021: {1:[1,2,3,4,5,6,7,8,9,10,16,17,23,24,30,31],2:[6,7,13,14,20,21,22,23,27,28],3:[6,7,8,13,14,20,21,27,28],4:[3,4,10,11,17,18,24,25,30],5:[1,2,3,8,9,10,15,16,22,23,29,30],6:[5,6,11,12,13,14,19,20,26,27],7:[3,4,10,11,17,18,24,25,31],8:[1,7,8,14,15,21,22,28,29],9:[4,5,11,12,18,19,25,26],10:[2,3,9,10,16,17,23,24,30,31],11:[3,4,6,7,13,14,20,21,27,28],12:[4,5,11,12,18,19,25,26,31]}\n",
    "}\n",
    "holidays = pd.DataFrame(list(itertools.chain.from_iterable(list(itertools.chain.from_iterable([[[date(year,month,day) for day in days] for month,days in v.items()] for year,v in holidays.items()])))),columns=['date'])\n",
    "holidays.date = pd.to_datetime(holidays.date)\n",
    "holidays['is_holiday'] = 1\n",
    "\n",
    "df = read_files()\n",
    "df = prepare_features(df, group_excl=['other_groups','ods2exa_group'])\n",
    "df = sample_features(df)\n",
    "df = scale_features(df)\n",
    "#df = dummy_features(df, holidays)\n",
    "df.to_csv('clear_data/rm_features.csv', ';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
